{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"415cd7bda13fc463692100ffbecbd2c9c795e868"},"cell_type":"code","source":"\nprint(train.head())\nprint(train.shape)\n#print(test.head())\n#print(test.shape)\n#629.145.480 629 milions rows for easy and fast processing get only first 10.000.000 10 milions rows\nsmall_train=train[0:10000000]\nsmall_train.shape\n#plot acustic data secuence first 10 milions rows\nfig,ax=plt.subplots(2,1,figsize=(17,17))\nsmall_train['acoustic_data'].plot(figsize=(14,5),ax=ax[0])\nsmall_train['time_to_failure'].plot(figsize=(14,5),ax=ax[1])\n#lets try to catch a earthquake moment\n#629.145.480 629 milions rows for easy and fast processing get only first 10.000.000 10 milions rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"248e70d2f34736dcdf20b2baa314967692f21707"},"cell_type":"code","source":"#we whant check few acustic data before and after earthquake\nfirst_quake=small_train[(small_train['time_to_failure']>small_train['time_to_failure'].shift(1))].head().index[0]\ncatch_train=train[first_quake-10000:first_quake+10000]\ncatch_train.shape\n\n#plot acustic data secuence first 10 milions rows\nfig,ax=plt.subplots(2,1,figsize=(17,17))\ncatch_train['acoustic_data'].plot(figsize=(14,5),ax=ax[0])\ncatch_train['time_to_failure'].plot(figsize=(14,5),ax=ax[1])\n#calculate time between acustics signals\nsmall_train['time-1'] = small_train['time_to_failure'].shift(-1)\nsmall_train['dif_time'] = small_train['time_to_failure']-small_train['time-1']\nprint(\"Mean time between signals-->\",small_train['dif_time'].mean(),\"MAX time between signals-->\",small_train['dif_time'].max(),\"MIN time between signals-->\",small_train['dif_time'].min())\n#small_train['dif_time'].plot(figsize=(14,5))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4314e79d6002386036ea5b38cda5000dc5955041"},"cell_type":"code","source":"#we try to do agrupations of N_SIGNALS\nGROUPS=250\n\ndef c_std(series):\n    return np.std(series)\n\nwindows=[2,3,5,8,13,21,34]\ndef getsample(input_set):\n    #final_sample=input_set\n    final_sample=pd.DataFrame(np.array(input_set).reshape((len(input_set),1)),columns=['acoustic_data'])\n    final_sample.index = pd.to_datetime(final_sample.index,unit=\"s\")\n    #print(\"final_sample\",final_sample.shape)\n    mdata= final_sample.resample(str(GROUPS)+\"s\").agg(\n        #{'acoustic_data' : ['first',max,min,'last','mean',c_std]    \n         {'acoustic_data' : ['first',max,min,'last']    \n        }    \n    )\n    mdata.columns=mdata.columns.droplevel(0)\n    #print(\"mdata\",mdata.shape)\n\n    for window in windows:\n        mdata['mafirst{}'.format(window)]=mdata['first'].rolling(window).mean()\n        mdata['mamax{}'.format(window)]=mdata['max'].rolling(window).mean()\n        mdata['mamin{}'.format(window)]=mdata['min'].rolling(window).mean()\n        mdata['malast{}'.format(window)]=mdata['last'].rolling(window).mean()\n   #     mdata['mamean{}'.format(window)]=mdata['mean'].rolling(window).mean()\n   #     mdata['macstd{}'.format(window)]=mdata['c_std'].rolling(window).mean()                \n    mdata=(mdata[windows[-1]:]-5)/3\n    #for x in mdata.columns:\n     #   mdata[x]=(mdata[x]-mdata[x].min())/(mdata[x].max-mdata[x].min())\n    return mdata\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0ff6038e7fae6c9e15431ca77f359987f49a374"},"cell_type":"code","source":"randitem=123234\nNUM_INPUT_ITEMS=150000\ndemo=train[randitem:randitem+NUM_INPUT_ITEMS]\n#print(demo.head())\nfinal=getsample(demo[\"acoustic_data\"])\nprint(final)\nprint(final.shape) #means 48 features\nNUM_STEPS=final.shape[0]\nFEATURES=final.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1056a11f3046dcd23e4759adce038146ada5c2fc"},"cell_type":"code","source":"NUM_INPUT_ITEMS=150000\nMAX_ITEM=train.shape[0]-NUM_INPUT_ITEMS\nprint(MAX_ITEM)\nBATCH_SIZE=32\ndef generator():\n    while True:\n        X_train=np.zeros((BATCH_SIZE,NUM_STEPS,FEATURES))\n        y_train=np.zeros((BATCH_SIZE,1))\n        \n        for x in range(BATCH_SIZE):            \n            while True:\n                start=np.random.randint(0,MAX_ITEM)\n                pd_sample=train[start:start+NUM_INPUT_ITEMS]      \n                #print(pd_sample.shape)\n                npdata=np.array(getsample(pd_sample[\"acoustic_data\"]))     \n                if npdata.shape[0]>=NUM_STEPS:\n                    break                      \n                \n            #NORM\n            #npdata=np.array((pd_sample[\"acoustic_data\"]-MIN)/(MAX-MIN))            \n            #STAND\n            #npdata=np.array((pd_sample[\"acoustic_data\"]-MEAN)/STD)\n            #print(npdata.shape)\n            npdata=npdata.reshape(NUM_STEPS,FEATURES)                            \n            # y_train[x]=pd_sample['time_to_failure'][NUM_INPUT_ITEMS-1]\n            #print(pd_sample)\n            y_train[x]=(np.array(pd_sample['time_to_failure'])[NUM_INPUT_ITEMS-1])/16\n            X_train[x]=npdata\n        yield X_train,y_train\nX,y=next(generator())    \nprint(X.shape)\nprint(y.shape)\nprint(X)\nprint(y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4c0b9efc0835106660dc2cd7bbbf4ecdeea5c2d"},"cell_type":"code","source":"# Define model\nfrom keras.models import Sequential\nfrom keras.layers import Dense,LSTM,Bidirectional,CuDNNGRU\nfrom keras.optimizers import adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\nfrom keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\ndef root_mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1)+0.0000001)\ndef cust_mae(y_true, y_pred):\n    return K.mean(K.abs((K.exp(y_pred) - K.exp(y_true))), axis=-1)+0.0000001\n\ndef cust_maev2(y_true, y_pred):\n    return K.mean(K.abs((((y_pred)*16) - ((y_true)*16))), axis=-1)+0.0000001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a457b397fd52db45e733116211e74f43b706036"},"cell_type":"code","source":"class Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim\n    \ninp = Input(shape=(NUM_STEPS,FEATURES))\nx = Bidirectional(CuDNNGRU(64, return_sequences=True))(inp)\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x)\nconc = concatenate([avg_pool, max_pool])\nconc = Dense(64, activation=\"relu\")(conc)\nconc = Dropout(0.1)(conc)\noutp = Dense(1,activation=\"sigmoid\")(conc)\n#outp = Dense(1, activation=\"sigmoid\")(conc)\n\nmodel = Model(inputs=inp, outputs=outp)\n\nprint(\"DONE\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c0145d7381cdfc4c8fe5d655c91848d25c9235d"},"cell_type":"code","source":"\n\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, monitor='loss',save_best_only=True, mode='auto')\nmodel.compile(loss='mae', optimizer='adam', metrics=['mae',cust_mae,cust_maev2])\n#model = Sequential()\n#model.add(CuDNNGRU(48, input_shape=(NUM_STEPS, FEATURES)))\n#model.add(Dense(10, activation='relu'))\n#model.add((LSTM(120, return_sequences=True,input_shape=(NUM_STEPS, FEATURES))))\n#model.add((LSTM(60, return_sequences=False)))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dense(1))\n\n# Compile and fit model\n#model.compile(optimizer=adam(), loss=\"logcosh\",metrics=['mae',cust_mae])\n#model.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3ab7322565cd3636db4f7155932fb0d09dcf392"},"cell_type":"code","source":"history = model.fit_generator(generator(),\n                              steps_per_epoch=100,\n                              epochs=80,\n                              verbose=1,\n                              callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"095e281255b0bcab73a2c9d3f005d99183d5d2a6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01b8d47adda17d7a6881be1f79a67ad25b29efc3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c782e901e6b46b498997f010243cc0bdf808d39c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"debbb4a4df53bce8ae732dabcee75a8b3e47acfd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e9c9d162b8568b386db5e182e2177e9c09f1bab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3c4cdef2c6bbfb0c91d23d5d03793939d0b17e8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1c61fde02dda1c627d7dc9f8ab8e653662b7063"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42164e068feac38e871e2f15760de5191e9a0d5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef73934994c80b100706e3c4025d6b1b3231a54"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ef91118c113926c192dc8dd5cc116a9b3887b5a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0045a75c4459171908533d5a2ee590fa59f48e04"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83587f7357f20a5da9dfd11d3b588bab91f89512"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b593d0da475a02660c9ddcea7593fa73b7d1c756"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db487eb4dc0acd8a6b7ce1513ab4f69d832aab5d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}